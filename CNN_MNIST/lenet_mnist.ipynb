{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_dataata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepNN(x):\n",
    "    # Reshape input data.\n",
    "    with tf.name_scope('reshape'):\n",
    "        x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    \n",
    "    # First convolution layer.\n",
    "    with tf.name_scope('conv1'):\n",
    "        W_conv1 = weight_variable([5,5,1,32])\n",
    "        b_conv1 = bias_variable([32])\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "        \n",
    "    ## Pooling layer.\n",
    "    with tf.name_scope('pool1'):\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "    \n",
    "    ## Convolution layer.\n",
    "    with tf.name_scope('conv2'):\n",
    "        W_conv2 = weight_variable([5,5,32,64])\n",
    "        b_conv2 = bias_variable([64])\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "        \n",
    "    ## Second pooling layer.\n",
    "    with tf.name_scope('pool2'):\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "        \n",
    "    ##fully connected layer.\n",
    "    with tf.name_scope('fc1'):\n",
    "        W_fc1 = weight_variable([7 * 7 * 64 , 1024])\n",
    "        b_fc1 = bias_variable([1024])\n",
    "        \n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "        \n",
    "    ## Dropout layer.\n",
    "    with tf.name_scope('dropout'):\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "        \n",
    "    ## Fully connected layer 2.\n",
    "    with tf.name_scope('fc2'):\n",
    "        W_fc2 = weight_variable([1024, 10])\n",
    "        b_fc2 = bias_variable([10])\n",
    "        y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "        \n",
    "    return y_conv, keep_prob\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides = [1,1,1,1], padding= 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev= 0.1)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "  # Import data\n",
    "    mnist = input_data.read_data_sets('/tmp/tensorflow/mnist/input_data', one_hot=True)\n",
    "\n",
    "  # Create the model\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "  # Define loss and optimizer\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "  # Build the graph for the deep net\n",
    "    y_conv, keep_prob = deepNN(x)\n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_,\n",
    "                                                            logits=y_conv)\n",
    "    cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "    with tf.name_scope('adam_optimizer'):\n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "        correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "    \n",
    "    accuracy = tf.reduce_mean(correct_prediction)\n",
    "\n",
    "    graph_location = tempfile.mkdtemp()\n",
    "    print('Saving graph to: %s' % graph_location)\n",
    "    train_writer = tf.summary.FileWriter(graph_location)\n",
    "    train_writer.add_graph(tf.get_default_graph())\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for i in range(2000):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        if i % 100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "        sess.run(train_step, feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    print(\"Testing Accuracy is : \")\n",
    "    print(sess.run(accuracy, feed_dict = {x : mnist.test.images, y_ : mnist.test.labels, keep_prob : 1.0}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/tensorflow/mnist/input_data\\train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data\\t10k-labels-idx1-ubyte.gz\n",
      "Saving graph to: C:\\Users\\lolla\\AppData\\Local\\Temp\\tmpo6_d0882\n",
      "step 0, training accuracy 0.04\n",
      "step 100, training accuracy 0.82\n",
      "step 200, training accuracy 0.94\n",
      "step 300, training accuracy 0.88\n",
      "step 400, training accuracy 0.9\n",
      "step 500, training accuracy 1\n",
      "step 600, training accuracy 0.98\n",
      "step 700, training accuracy 0.96\n",
      "step 800, training accuracy 0.96\n",
      "step 900, training accuracy 0.96\n",
      "step 1000, training accuracy 0.96\n",
      "step 1100, training accuracy 0.94\n",
      "step 1200, training accuracy 1\n",
      "step 1300, training accuracy 0.98\n",
      "step 1400, training accuracy 0.98\n",
      "step 1500, training accuracy 0.96\n",
      "step 1600, training accuracy 1\n"
     ]
    }
   ],
   "source": [
    "tf.app.run(main = main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
